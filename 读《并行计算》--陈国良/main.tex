\documentclass{article}

\usepackage{ctex}
\usepackage{cite}
\usepackage{bm}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{float}
\usepackage{stfloats}
\usepackage{placeins}
\usepackage{subfigure}
\usepackage{listings}
\usepackage{url}
\usepackage[linesnumbered,boxed,ruled,commentsnumbered]{algorithm2e}%%算法包，注意设置所需可选项
\usepackage{amsmath}
\newtheorem{definition}{定义}[section]
\newtheorem{theorem}{定理}[section]
\newtheorem{proof}{证明}[section]
\usepackage{setspace} 
\usepackage{diagbox}
\usepackage{multirow}
\usepackage[colorlinks,
linkcolor=blue,
anchorcolor=blue,
citecolor=blue]{hyperref}

\begin{document}
	\title{陈国良. 并行计算:结构·算法·编程[M]. 1999.}
	\author{屈彬}
	\maketitle
	
	\section{并行计算机系统及其结构模型}
		\subsection{并行计算（2019年7月2日）}
			\subsubsection{并行计算与计算科学}
				\begin{definition}[应用需求]
					应用需求分为三类，\textbf{计算密集}（Compute-Intensive）型应用，如大型科学工程计算与数值模拟；\textbf{数据密集}（Data-Intensive）型应用，如数字图书馆、数据仓库、数据挖掘和计算可视化等；\textbf{网络密集}（Network-Intensive）型应用，如协同工作、遥控和远程医疗诊断等。
				\end{definition}
				\begin{definition}[高性能计算和通信]
					High Performance Computing and Communication, HPCC。
				\end{definition}
				\begin{definition}[加速战略计算创新]
					Accelerated Strategic Computing Initiative, ASCI。
				\end{definition}
				\begin{definition}[美国能源部三大高性能计算实验室]
					Lawrence Livermore、Los Alamos、Sandia。
				\end{definition}
		\subsection{并行计算系统互连（2019年7月3日）}
			\subsubsection{系统互连}
				\begin{definition}[机群网络分类]
					\begin{enumerate}
						\item \textbf{系统域网络}：（System Area Network，SAN），连接短距离（3~25m）内的节点。
						\item \textbf{局域网络}：（Local Area Network，LAN），连接企事业单位内（500m~2km）内的节点。
						\item \textbf{节点内网络}：由\textbf{处理器总线}、\textbf{局部（本地）总线}、\textbf{存储器总线}构成。
						\item \textbf{小型机系统接口}：（Small Computer System Interface, SCSI）由\textbf{I/O总线}、\textbf{系统总线}构成。
					\end{enumerate}
				\end{definition}
				\begin{definition}[工作站机群]
					（Cluster of Workstations, COW），通过SAN/LAN互连的工作站组。
				\end{definition}
			\subsubsection{静态互连网络}
				\begin{definition}[对剖宽度]
					（Bisection Width）：将网络划分为两等分所必须剪去的最少边数。
				\end{definition}
			\subsubsection{动态互连网络}
				\begin{definition}[总线分类]
					常用总线包括PCI、VME、Multibus、SBus、Microchannel和IEEE Futurebus。
				\end{definition}
				\begin{enumerate}
					\item \textbf{本地总线}：（Local Bus），CPU板级上的总线。
					\item \textbf{存储器总线}：存储器板级上的总线，主要指内存与CPU互连的总线。
					\item \textbf{数据总线}：I/O与通信板级上的总线，例如硬盘与内存之间的总线，以及网卡。
				\end{enumerate}
			\subsubsection{标准互连网络分类}
				\begin{enumerate}
					\item \textbf{光纤分布式数据接口}（Fiber Distributed Data Interface, FDDI），采用双向光纤令牌环提供100~200Mb/s的数据传输。
					\item \textbf{快速以太网}主流的互连网络，第三代以太网数据传输速度可达1Gb/s。
					\item \textbf{myrinet}由Myricom公司生产的千兆位包开关网。
					\item \textbf{高性能并行接口}（High Performance Parallel Interface, HiPPI），主要用于构筑异构计算机系统。
					\item \textbf{异步传输模式}（Asynchronous Transfer Mode, ATM），在光纤通信基础上建立起来的一种新的宽带综合业务数字网（B-ISDN）的交换技术。
					\item \textbf{无线带宽}（InfiniBand）。
				\end{enumerate}
		\subsection{并行计算机体系结构（2019年7月4日）}
			\subsubsection{并行计算机结构模型}
				大型并行机系统一般可分为六类机器：
				\begin{enumerate}
					\item \textbf{单指令多数据流}：（Single Instruction Multiple-Data, SIMD）。
					\item \textbf{并行向量处理机}：（Parallel Vector Processor, PVP）。
					\item \textbf{对称多处理机}：（Symmetric Multiprocessor, SMP）。
					\item \textbf{大规模并行处理机}：（Massively Parallel Processor, MPP）。
					\item \textbf{工作站机群}：（Cluster of Workstations, COW）。
					\item \textbf{分布共享存储多处理机}：（Distributed Shared Memory, DSM）。
				\end{enumerate}
				除SIMD外，其余五种皆为MIMD。
			\subsubsection{并行计算机访存模型}
				\begin{enumerate}
					\item \textbf{均匀存储访问}：（Uniform Memory Access, UMA），其特点包括：物理存储器被所有处理器均匀共享；所有处理器访问任何存储单元取相同的时间；每台处理器可带私有cache；外围设备也可以一定形式共享。这种系统由于高度共享资源又被称为\textbf{紧耦合系统}（Tightly Coupled System）。多核同构CPU系统的存储模型属于典型的UMA模型。
					\item \textbf{非均匀存储访问}：（Nonuniform Memory Access, NUMA）。
					\item \textbf{全高速缓存存储访问}：（Cache-Only Memory Access, COMA）。
					\item \textbf{高速缓存一致性非均匀存储访问}：（Coherent-Cache Nonuniform Memory Access, CC-NUMA）。
					\item \textbf{非远程存储访问}：（No-Remote Memory Access, NORMA）。
				\end{enumerate}
			\subsubsection{并行计算机存储组织}
				\begin{definition}[层次存储技术]
					利用程序局部性，设置多级存储系统。底层的存储器通常具有容量大、速度慢、成本低的特点，高层的存储器通常具有容量小、速度快、成本高的特点。层次存储技术出现的目的在于寻找性能与成本之间的平衡。
				\end{definition}
				\begin{definition}[高速缓存一致性问题]
					当处理器将新数据写入高层存储器时，需保证其他层次中存储器的数据对应的位置具有相同的副本。
				\end{definition}
	\section{当代并行计算机系统介绍}
	跳过第2章，它的内容与第1章存在大量重复。
	\section{并行计算性能评测}		
		\subsection{并行计算机的一些基本性能指标（2019年7月5日）}
			\subsubsection{CPU和存储器的某些基本性能指标}
				\begin{table}[H]
					\centering
					\begin{tabular}{|c|c|c|c|}
						\hline
						名称&符号&含意&单位\\
						\hline
						机器规模&$n$&处理器的数目&\\
						时钟速率&$f$&时钟周期长度的倒数&MHz\\
						工作负载&$W$&计算操作的数目&Mflop\\
						顺序执行时间&$T_{1}$&程序在单处理机上的运行时间&s（秒）\\
						并行执行时间&$T_{n}$&程序在并行机上的运行时间&s（秒）\\
						速度&$R_{n}=W/T_{n}$&每秒百万次浮点运算&Mflops\\
						加速&$S_{n}=T_{1}/T_{n}$&衡量并行机有多快&\\
						效率&$E_{n}=S_{n}/n$&衡量处理器的利用率&\\
						峰值速度&$R_{peak}=nR_{peak}^{'}$&所有处理器峰值速度之积&Mflops\\
						顺序峰值速度&$R_{peak}^{'}$&单个处理器的峰值速度&Mflops\\
						利用率&$U=R_{n}/R_{peak}$&可达速度与峰值速度之比&\\
						通信延迟&$t_{0}$&传送0-字节或单字的时间&$\mu$s\\
						渐进带宽&$r_{\inf}$&传送长消息的通信速率&MD/s\\
						\hline
					\end{tabular}
				\end{table}
			\subsubsection{通信开销测量方法}
				\begin{enumerate}
					\item \textbf{乒-乓方法}：（Ping-Pong Scheme）适用于一对节点之间通信开销的测量。
					\item \textbf{热土豆法}：（Hot-Potato），也称作\textbf{救火队法}（Fire-Brigade），适用于测量多个节点（两个以上）以环形方式通信，数据包传递一圈的通信开销。
				\end{enumerate}
				理论\textbf{点到点通信开销}$t(m)$是消息长度$m$（字节）的线性函数：
				$$t(m)=t_{0}+m/r_{\inf}$$
				其中$t_{0}$是通信启动时间（$\mu$s），$r_{\inf}$是渐进带宽（MB/s）。
			\subsubsection{机器的成本、价格与性能/价格比}
				内容比较零碎，跳过。
		\subsection{加速比性能定律（2019年7月6日）}
			\subsubsection{Amdahl定律}
			\subsubsection{Gustafson定律}
			\subsubsection{Sun和Ni定律}
	\section{并行算法的设计基础}
		出于PAC比赛的需求，暂时先跳过第三章。
		\subsection{并行算法的基础知识}
		\subsection{并行计算模型（2019年7月7日）}
			并行计算模型是硬件和软件之间的一种桥梁（大雾，什么叫作``桥梁''），使用它能够设计分析算法，在其上高级语言能被有效地编译且能够用硬件实现。（我觉得作者没有把并行计算模型的用途讲清楚）
			\subsubsection{PRAM模型}
				即\textbf{并行随机存储机器}（Parallel Random Access Machine, PRAM），是一种抽象的并行计算同步模型。在这种模型中，假定存在着一个容量无限大的共享存储器；有多个同构处理器；在任何时刻各处理器均可通过共享存储单元相互交换数据以实现同步。根据对处理器读写时序的限制，又可分类为：
				\begin{enumerate}
					\item \textbf{不允许同时读和同时写}（Exclusive=Read and Exclusive-Write）的PRAM模型，记作\textbf{PRAM-EREW}。
					\item \textbf{允许同时读不允许同时写}（Concurrent-Read and Exclusive-Write）的PRAM模型，记作\textbf{PRAM-CREW}。
					\item \textbf{允许同时读和同时写}（Concurrent-Read and Concurrent-Write）的PRAM模型，记作\textbf{PRAM-CRCW}。
				\end{enumerate}
				不过，允许同时写显然是不现实的，所以对PRAM-CRCW模型做了进一步的约定：
				\begin{enumerate}
					\item \textbf{CPRAM-CRCW}：公共的PRAM-CRCW，只允许所有的处理器同时写相同的数。
					\item \textbf{PPRAM-CRCW}：优先的PRAM-CRCW，只允许最优先的处理器先写。
					\item \textbf{APRAM-CRCW}：任意的PRAM-CRCW，允许任意处理器自由写。
				\end{enumerate}
			\subsubsection{异步PRAM模型}
				记作APRAM，它的特点是\textbf{分相}（Phase），每个处理器都有其私有存储（书里称作``局存''）、私有时钟（书里称作``局部时钟''）和局部程序；处理器之间通过共享全局存储器进行通信；无全局时钟，各处理器异步地独立执行各自的指令；若处理器之间存在任何时序依赖关系（书中称作``时间依赖关系''），须通过插入同步路障（Synchronization Barrier）以保持依赖源和目标的执行顺序。
				
				APRAM模型具有四种访存指令：
				\begin{enumerate}
					\item \textbf{全局读}：将全局存储单元中的内容读入私有存储单元中。
					\item \textbf{局部操作}：对局存中的数执行操作，其结果是存入局存中。
					\item \textbf{全局写}：将局存单元中的内容写入全局存储单元中。
					\item \textbf{同步}：同步是计算中的一个逻辑点，在该点各处理器均需等待别的处理器到达后才能继续执行其局部程序。
				\end{enumerate}
			\subsubsection{BSP模型}
				整体同步计算模型（Bulk Synchronous Parallel），字面含义是``大''同步模型，该模型使用了三个属性描述：模块（Components）、选路器（Router）和同步路障器执行时间L（中文又称“超级步”）。BSP是一种MIMD-DM（DM：distributed memory）模型。
				
				在一个超级步中，每个处理器执行各自的局部计算，通过选路器接收和发送消息；然后作一全局检查（同步），以确定当前超级步是否已由所有的处理器完成；然后前进到下一个超级步。
				
				在分析BSP模型的性能时，假定局部操作可在一个超级步内完成。在每一超级步中，一个处理器至多发送或接收$h$条消息（称为\textbf{h-relation}）。假定$s$是传输建立时间，$g$定义为每秒处理器所能完成的局部计算数目与每秒选路器所能传输的数据量之比，那么传送$h$条消息的时间开销为$gh+s$，若$gh\geq 2s$，则超级步步长$L\geq gh$（为什么？）。硬件可设置L的下限（例如宽的通信带宽减小$g$），而软件可设置L的上限（例如并行粒度越大，L越大）。
			\subsubsection{logP模型}
				
\end{document}