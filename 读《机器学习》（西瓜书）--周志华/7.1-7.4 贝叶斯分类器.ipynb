{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 10px\">\n",
    "<a id=\"ref1\"></a>\n",
    "<center>1 学习笔记</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1\t贝叶斯分类器与多分类任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 贝叶斯分类器的基本原理及极大似然估计的作用\n",
    "### 6.2.1 贝叶斯分类器的基本原理\n",
    "贝叶斯分类器的分类原理是通过某对象的先验概率P(c)，利用贝叶斯公式计算出其后验概率，即该对象属于某一类的概率，选择具有最大后验概率的类作为对象所属的类。\n",
    "### 6.2.2 极大似然估计的作用\n",
    "极大似然估计的作用是估计类条件概率P(x|c)，根据数据采样估计概率分布参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3\t朴素贝叶斯分类器与半朴素贝叶斯分类器的原理与应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 朴素贝叶斯算法\n",
    "朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布，然后基于此模型，对给定的输入 x ，利用贝叶斯定理，利用贝叶斯定理求出后验概率最大的输出 y\n",
    "\n",
    "<p>输入：训练数据$D=\\left\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)\\right\\}$，其中$x_i=(x_i^{(1)},x_i^{(2)},\\cdots,x_i^{(n)})$，$x_i^{(j)}$是第$i$个样本的第$j$个特征，$x_i^{(j)}\\in\\left\\{a_{j1},a_{j2},\\cdots,a_{jS_j}\\right\\}^T$，$a_{jl}$是第$j$个特征可能取的第$l$个值，$j=1,2,\\cdots,n$，$l=1,2,\\cdots,S_j$，$y_i\\in\\left\\{c_1,c_2,\\cdots,c_K\\right\\}$；实例$x=(x^{(1)},x^{(2)},\\cdots,x^{(n)})^T$</p>\n",
    "<p>输出：实例$x$的分类</p>\n",
    "<p>算法步骤如下：</p>\n",
    "<ul>\n",
    "    <li>计算先验概率和条件概率\n",
    "        $$P(Y=c_k)=\\frac{\\sum_{i=1}^NI(y_i=c_k)}{N},k=1,2,\\cdots,K$$\n",
    "        $$$$\n",
    "        $$P(X^{(j)}=a_{jl}|Y=c_k)=\\frac{\\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)}{\\sum_{i=1}^NI(y_i=c_k)}$$\n",
    "        $$$$\n",
    "        $$j=1,2,\\cdots,n;l=1,2,\\cdots,S_j;k=1,2,\\cdots,K$$</li><br>\n",
    "    <li>对于给定的实例$x=(x^{(1)},x^{(2)},\\cdots,x^{(n)})^T$，计算：$$P(Y=c_k)\\prod_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k),k=1,2,\\cdots,K$$</li><br>\n",
    "    <li>确定实例$x$的类$$y=\\arg\\max_{c_k}P(Y=c_k)\\prod_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k),k=1,2,\\cdots,K$$</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 半朴素贝叶斯算法\n",
    "半朴素贝叶斯法不同于朴素贝叶斯法，它对特征条件独立性假设进行了一定程度的放松。基本想法是适当考虑一部分特征间的相互信息，从而既不需进行完全联合概率计算，又不至于彻底忽略了比较强的依赖关系。\n",
    "<p>半朴素贝叶斯分类起常用的策略为One-Dependent Estimator，即假设每个属性在类别之外最多仅依赖于一个其他属性，即：</p>\n",
    "\n",
    "$$P(c|x)\\alpha P(c) \\prod_{i=1}^{d}P( x_i  |c, pa_i )$$\n",
    "\n",
    "<p>其中$pa_i$为属性$x_i$所依赖的属性，称为$x_i$的父属性。若父属性$pa_i$已知，则可以采用半朴素贝叶斯算法的方法来估计概率值。至于确定超父属性，最直接的做法是假设所有属性都依赖于同一个属性，然后通过交叉验证等模型选择方法来确定，这种做法我们称之为Super-Parent ODE方法。</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 10px\">\n",
    "<a id=\"ref2\"></a>\n",
    "<center>2 算法实现</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯分类器实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.PLabels=dict()\n",
    "        self.NBClassify=dict()        \n",
    "    \n",
    "    def train(self,data):\n",
    "        labels = data[:, -1]\n",
    "        label_list=list(set(labels))\n",
    "        PLabels=dict()\n",
    "        NBClassify=dict()\n",
    "        for label in label_list:\n",
    "            PLabels[label]=(sum([1 for l in labels if l==label])+1 )/ len(labels)\n",
    "            NBClassify[label]=dict()\n",
    "            \n",
    "        for label in NBClassify.keys():\n",
    "            sub_data = data[data[:, -1] == label]\n",
    "            sub_data = np.array(sub_data)\n",
    "            for k in range(sub_data.shape[1]):\n",
    "                NBClassify[label][k] = dict()\n",
    "                tags = list(set(data[:, k]))\n",
    "                d = sub_data[:, k]\n",
    "                for tag in tags:\n",
    "                    NBClassify[label][k][tag] = (sum([1 for i in d\n",
    "                    if i == tag])+1)/len(d)\n",
    "        self.PLabels=PLabels\n",
    "        self.NBClassify=NBClassify\n",
    "\n",
    "    def predict(self,data):\n",
    "        predict_vec = list()\n",
    "        for sample in data:\n",
    "            pl=dict()\n",
    "            for i in self.PLabels.keys():\n",
    "                pl[i] = np.math.log(self.PLabels[i], 2) \n",
    "                #pl[i]=tf.log(self.PLabels[i])\n",
    "            for label in self.NBClassify.keys():\n",
    "                for k, tag in enumerate(sample):\n",
    "                    pl[label] += np.math.log(self.NBClassify[label][k][tag], 2)  \n",
    "                    #pl[label] += tf.log(self.NBClassify[label][k][tag]) \n",
    "            predict_vec.append(max(pl,key=pl.get))\n",
    "            #predict_vec.append(tf.argmax(pl))\n",
    "        return np.array(predict_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2）对比分析使用朴素贝叶斯分类器与半朴素贝叶斯分类器编写的天气预报模型的差异。\n",
    "## 半朴素贝叶斯分类器\n",
    "<p>这里我们采用了独依赖分类器AODE（Averaged One-Dependent Estimator），即：</p>\n",
    "\n",
    "$$P(c|x)\\alpha \\sum_{i=1 }^{d}  P(c) \\prod_{i=1}^{d}P( x_i  |c, pa_i ) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiNaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.PLabels=dict()\n",
    "        self.SNBClassify=dict()\n",
    "    \n",
    "    def train(self,data):\n",
    "        labels = data[:, -1]\n",
    "        label_list=list(set(labels))\n",
    "        PLabels=dict()\n",
    "        SNBClassify=dict()\n",
    "        for label in label_list:\n",
    "            PLabels[label]=dict()\n",
    "            sub_data = data[data[:, -1] == label]\n",
    "            sub_data = np.array(sub_data)\n",
    "            for k in range(sub_data.shape[1]):\n",
    "                PLabels[label][k]=dict()\n",
    "                tags=list(set(data[:,k]))\n",
    "                d=sub_data[:,k]\n",
    "                for tag in tags:\n",
    "                    PLabels[label][k][tag]=(sum([1 for i in d if i==tag])+1 )/ len(data)    \n",
    "            \n",
    "        for label in label_list:\n",
    "            SNBClassify[label]=dict()\n",
    "            sub_data = data[data[:, -1] == label]\n",
    "            sub_data = np.array(sub_data)\n",
    "            for k in range(sub_data.shape[1]):\n",
    "                SNBClassify[label][k] = dict()\n",
    "                tags = list(set(data[:, k]))\n",
    "                for tag in tags:\n",
    "                    SNBClassify[label][k][tag]=dict()\n",
    "                    sub_sub_data=sub_data[sub_data[:,k]==tag]\n",
    "                    if len(sub_sub_data)>=30:\n",
    "                        for j in range(sub_sub_data.shape[1]):\n",
    "                            SNBClassify[label][k][tag][j]=dict()\n",
    "                            stags=list(set(sub_sub_data[:,j]))\n",
    "                            d=sub_sub_data[:,j]\n",
    "                            for stag in stags:\n",
    "                                SNBClassify[label][k][tag][j][stag] = (sum([1 for i in d if i == stag])+1)/(len(sub_sub_data))\n",
    "        self.PLabels=PLabels\n",
    "        self.SNBClassify=SNBClassify\n",
    "\n",
    "    def predict(self,data):\n",
    "        predict_vec = list()\n",
    "        for sample in data:\n",
    "            pl=dict()\n",
    "            for label in self.PLabels.keys():\n",
    "                p = list()\n",
    "                for k, tag in enumerate(sample):\n",
    "                    pcx=np.math.log(self.PLabels[label][k][tag], 2)\n",
    "                    for j, jtag in enumerate(sample):\n",
    "                        if j in self.SNBClassify[label][k][tag].keys():\n",
    "                            if jtag in self.SNBClassify[label][k][tag][j].keys():\n",
    "                                pcx+=np.math.log(self.SNBClassify[label][k][tag][j][jtag], 2)\n",
    "                    p.append(pcx)\n",
    "                p=np.array(p)\n",
    "                pl[label]= np.sum(p)        \n",
    "            predict_vec.append(max(pl,key=pl.get))\n",
    "        return np.array(predict_vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
